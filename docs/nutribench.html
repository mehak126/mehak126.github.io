<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>Scrolling Nav - Start Bootstrap Template</title>
    <!-- <link rel="icon" type="image/x-icon" href="assets/favicon.ico" /> -->
    <!-- Core theme CSS (includes Bootstrap)-->
    <!-- <link href="css/styles.css" rel="stylesheet" /> -->
    <link rel="stylesheet" href="./nutribench_template/dist/css/styles.css">
    <script src="./nutribench_template/dist/js/scripts.js"></script>
</head>

<body id="page-top">
    <!-- Navigation-->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
        <div class="container px-4">
            <a class="navbar-brand" href="#page-top">NutriBench</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
                aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span
                    class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link" href="#eval">Benchmarking LLMs</a></li>
                    <li class="nav-item"><a class="nav-link" href="#contact">Contact</a></li>
                </ul>
            </div>
        </div>
    </nav>
    <!-- Header-->
    <header class="bg-primary bg-gradient text-dark">
        <div class="container px-4 text-center">
            <h1 class="fw-bolder">NutriBench</h1>
            <p class="lead">A Dataset for Evaluating Large Language Models in Carbohydrate Estimation from Meal
                Descriptions</p>
            <p class="author-names">Andong Hua<sup>*</sup>, Mehak Preet Dhaliwal<sup>*</sup>, Yao Qin</p>
            <p class="author-names">University of California, Santa Barbara</p>
            <a class="btn btn-lg btn-dark" href="https://github.com/DongXzz/NutriBench">Data Link</a>
        </div>
    </header>
    <!-- About section-->
    <section id="about">
        <div class="container px-4">
            <div class="row gx-4 justify-content-center">
                <div class="col-lg-8">
                    <!-- <div class="col-lg-7">
                        <video class="img-fluid rounded mb-4 mb-lg-0" controls autoplay loop muted poster="demo_cover">
                            <source src="./nutribench_template/dist/assets/demo_vid.mp4" type="video/mp4">
                            Your browser does not support the video.
                        </video>
                    </div> -->
                    <h2>About</h2>
                    <p class="lead"> NutriBench is the first publicly available natural language meal description based
                        nutrition benchmark. The dataset consists of 5,000 human-verified meal descriptions with
                        macro-nutrient labels, including carbohydrates, proteins, fats, and calories. NutriBench can be
                        used to evaluate and benchmark Large Language Models (LLMs) on the task of nutrition estimation.
                        The video below shows examples of NutriBench queries and responses by GPT-3.5 with
                        Chain-of-Thought (CoT) prompting for carbohydrate estimation.

                        <video class="img-fluid rounded mb-4 mb-lg-0" controls autoplay loop muted poster="demo_cover">
                            <source src="./nutribench_template/dist/assets/demo_vid.mp4" type="video/mp4">
                            Your browser does not support the video.
                        </video>


                        NutriBench is constructed from FoodData Central (FDC), the food composition information
                        center of the US Department of Agriculture (USDA). We utilize GPT-3.5 to generate natural
                        language meal descriptions from food items sampled from a cleaned and filtered FDC. We also
                        conduct two rounds of human verification to ensure the quality of NutriBench. The image below
                        shows the end-to-end construction pipeline of NutriBench. <br><br>

                        <img class="img-fluid rounded mb-4 mb-lg-0"
                            src="./nutribench_template/dist/assets/Pipeline.jpeg" alt="NutriBench Construction Pipeline"
                            width="700" height="200">

                        <br><br>
                        NutriBench is divided into 15 subsets varying in complexity based on the number, servings, and
                        popularity of the food items in the meals and the specificity of serving size descriptions. This
                        ensures that the benchmark represents various challenging scenarios likely to be encountered in
                        the real world.
                    </p>
                </div>
            </div>
        </div>
    </section>
    <!-- Services section-->
    <section class="bg-light" id="eval">
        <div class="container px-4">
            <div class="row gx-4 justify-content-center">
                <div class="col-lg-8">
                    <h2>Benchmarking LLMs on Carbohyrate Estimation</h2>
                    <p class="lead">We benchmark the performance of seven state-of-the-art LLMs (GPT-3.5, Llama2-7B/70B,
                        Llama3-8B/70B, Alpaca-7B, MedAlpaca-7B) on the task of carbohydrate estimation with NutriBench.
                        We further employ four prompting strategies including (1) Baseline instructional prompting, (2)
                        Chain-of-Thought (CoT), (3) Retrieval Augmented Generation (RAG), and (4) RAG+CoT. The image
                        below shows the output by GPT-3.5 for the four prompting strategies for a NutriBench query.

                        <br><br>
                        <img class="img-fluid rounded mb-4 mb-lg-0" src="./nutribench_template/dist/assets/example.jpg"
                            alt="Example" width="1000" height="500">

                        <br><br>


                        Across all models, prompting methods, and data splits, we conducted 300 experiments to provide a
                        comprehensive insight into the current capabilities of LLMs in nutrition estimation. We also
                        conducted a human study involving expert and non-expert participants and found that LLMs can
                        provide more accurate and faster predictions over a range of complex queries. The image below
                        summarizes the results of our experiments, plotting the accuracy (absolute error < 7g) and
                            answer rate for all the methods on NutriBench. GPT-3.5 with CoT prompting achieves the
                            highest accuracy of 51.48%, with an answer rate of 89.80%. <br><br>
                            <img class="img-fluid rounded mb-4 mb-lg-0"
                                src="./nutribench_template/dist/assets/results.jpg" alt="Example" width="600"
                                height="300">

                            <br><br>
                    </p>
                </div>
            </div>
        </div>
    </section>
    <!-- Contact section-->
    <section id="contact">
        <div class="container px-4">
            <div class="row gx-4 justify-content-center">
                <div class="col-lg-8">
                    <h2>Contact</h2>
                    <p class="lead">For any questions, please contact the authors at {dongx1997,mdhaliwal}@ucsb.edu</p>
                </div>
            </div>
        </div>
    </section>
    <!-- Footer-->
    <footer class="py-5 bg-dark">
        <div class="container px-4">
            <p class="m-0 text-center text-white">Copyright &copy; Creative Commons Attribution Non Commercial Share
                Alike 4.0 (CC
                BY-NC-SA 4.0)</p>
        </div>
    </footer>
    <!-- Bootstrap core JS-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>
</body>

</html>